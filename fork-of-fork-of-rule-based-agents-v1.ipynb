{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.005815,
     "end_time": "2021-01-26T20:33:22.170756",
     "exception": false,
     "start_time": "2021-01-26T20:33:22.164941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Keep pulling same bandit as long as reward keeps coming!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T20:33:22.186305Z",
     "iopub.status.busy": "2021-01-26T20:33:22.185611Z",
     "iopub.status.idle": "2021-01-26T20:33:33.748479Z",
     "shell.execute_reply": "2021-01-26T20:33:33.747743Z"
    },
    "papermill": {
     "duration": 11.572983,
     "end_time": "2021-01-26T20:33:33.748626",
     "exception": false,
     "start_time": "2021-01-26T20:33:22.175643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle-environments in /opt/conda/lib/python3.7/site-packages (1.7.0)\r\n",
      "Collecting kaggle-environments\r\n",
      "  Downloading kaggle_environments-1.7.7-py2.py3-none-any.whl (107 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 107 kB 420 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kaggle-environments) (3.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kaggle-environments) (19.3.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kaggle-environments) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kaggle-environments) (0.16.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kaggle-environments) (3.1.1)\r\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kaggle-environments) (1.14.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonschema>=3.0.1->kaggle-environments) (3.1.0)\r\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0.1->kaggle-environments) (1.14.0)\r\n",
      "Installing collected packages: kaggle-environments\r\n",
      "  Attempting uninstall: kaggle-environments\r\n",
      "    Found existing installation: kaggle-environments 1.7.0\r\n",
      "    Uninstalling kaggle-environments-1.7.0:\r\n",
      "      Successfully uninstalled kaggle-environments-1.7.0\r\n",
      "Successfully installed kaggle-environments-1.7.7\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 21.0 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle-environments --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T20:33:33.771862Z",
     "iopub.status.busy": "2021-01-26T20:33:33.770944Z",
     "iopub.status.idle": "2021-01-26T20:33:33.774218Z",
     "shell.execute_reply": "2021-01-26T20:33:33.773721Z"
    },
    "papermill": {
     "duration": 0.016398,
     "end_time": "2021-01-26T20:33:33.774331",
     "exception": false,
     "start_time": "2021-01-26T20:33:33.757933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# observation = {\n",
    "#     'remainingOverageTime': 60,\n",
    "#     'agentIndex': 1, # 0 or 1\n",
    "#     'reward': 92, # total reward\n",
    "#     'step': 184, # [0-1999]\n",
    "#     'lastActions': [84, 94]\n",
    "# }\n",
    "\n",
    "# configuration:\n",
    "# {'episodeSteps': 2000,\n",
    "#  'actTimeout': 0.25,\n",
    "#  'runTimeout': 1200,\n",
    "#  'banditCount': 100,\n",
    "#  'decayRate': 0.97,\n",
    "#  'sampleResolution': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.008212,
     "end_time": "2021-01-26T20:33:33.791169",
     "exception": false,
     "start_time": "2021-01-26T20:33:33.782957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T20:33:33.813857Z",
     "iopub.status.busy": "2021-01-26T20:33:33.813212Z",
     "iopub.status.idle": "2021-01-26T20:33:34.034498Z",
     "shell.execute_reply": "2021-01-26T20:33:34.033958Z"
    },
    "papermill": {
     "duration": 0.234893,
     "end_time": "2021-01-26T20:33:34.034620",
     "exception": false,
     "start_time": "2021-01-26T20:33:33.799727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment football failed: No module named 'gfootball'\n"
     ]
    }
   ],
   "source": [
    "from kaggle_environments import make\n",
    "env = make(\"mab\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-26T20:33:34.061479Z",
     "iopub.status.busy": "2021-01-26T20:33:34.060599Z",
     "iopub.status.idle": "2021-01-26T20:33:34.065900Z",
     "shell.execute_reply": "2021-01-26T20:33:34.065329Z"
    },
    "papermill": {
     "duration": 0.022113,
     "end_time": "2021-01-26T20:33:34.066032",
     "exception": false,
     "start_time": "2021-01-26T20:33:34.043919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mybest.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mybest.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, os, datetime, math\n",
    "from collections import defaultdict\n",
    "from scipy.stats import beta\n",
    "\n",
    "# random number generator\n",
    "rng = np.random.default_rng(13)\n",
    "\n",
    "# belief distribution for the thresholds of each arm\n",
    "time_since_op_pull = np.zeros(100)\n",
    "action_counts = np.zeros((100, 2), np.int16)\n",
    "supports = np.tile(np.arange(101.0), (100, 1))\n",
    "beliefs = 1e6 + beta(2,2).pdf(np.linspace(0,1,101))\n",
    "beliefs = np.full((100, 101), beliefs/beliefs.sum())\n",
    "\n",
    "# game history\n",
    "step = 0\n",
    "my_pulls = np.array([], dtype=np.int)\n",
    "op_pulls = np.array([], dtype=np.int)\n",
    "results = np.array([], dtype=np.int)\n",
    "\n",
    "\n",
    "total_reward = 0\n",
    "bandit_dict = {}\n",
    "\n",
    "def set_seed(my_seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(my_seed)\n",
    "    random.seed(my_seed)\n",
    "    np.random.seed(my_seed)\n",
    "\n",
    "def get_next_bandit():\n",
    "    best_bandit = 0\n",
    "    best_bandit_expected = 0\n",
    "    for bnd in bandit_dict:\n",
    "        expect = (bandit_dict[bnd]['win'] - bandit_dict[bnd]['loss'] + bandit_dict[bnd]['opp'] - (bandit_dict[bnd]['opp']>0)*1.5) \\\n",
    "                 / (bandit_dict[bnd]['win'] + bandit_dict[bnd]['loss'] + bandit_dict[bnd]['opp']) \\\n",
    "                * math.pow(0.97, bandit_dict[bnd]['win'] + bandit_dict[bnd]['loss'] + bandit_dict[bnd]['opp'])\n",
    "        if expect > best_bandit_expected:\n",
    "            best_bandit_expected = expect\n",
    "            best_bandit = bnd\n",
    "    return best_bandit\n",
    "\n",
    "my_action_list = []\n",
    "op_action_list = []\n",
    "pre_wins = []\n",
    "\n",
    "\n",
    "op_continue_cnt_dict = defaultdict(int)\n",
    "\n",
    "# could add opposite tilting to those only pulled once?\n",
    "def sample():\n",
    "    window = 10\n",
    "    hist = np.bincount(op_pulls[-window:], minlength=100).reshape(100, 1)\n",
    "    hist = np.where(hist >= 2.0, hist, 0.0)\n",
    "\n",
    "    tilted = (np.ceil(supports) ** hist) * beliefs\n",
    "    tilted = tilted / tilted.sum(axis=1, keepdims=True)\n",
    "\n",
    "    hist = np.bincount(op_pulls[-101:], minlength=100).reshape(100, 1)\n",
    "    hist = np.where(hist == 1, 1.0, 0.0)\n",
    "    hist[op_pulls[-1]] = 0.0\n",
    "\n",
    "    tilted = ((101.0 - np.ceil(supports)) ** hist) * tilted\n",
    "    tilted = tilted / tilted.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # get optimistic estimate of threshold\n",
    "    optimism = 1.0\n",
    "    mean = np.sum(supports * tilted, axis=1, keepdims=True)\n",
    "    var = np.sum(((supports - mean) ** 2) * tilted, axis=1, keepdims=True)\n",
    "    estimate = np.squeeze(mean + optimism * np.sqrt(var))\n",
    "    \n",
    "    # choose the arm with highest estimate\n",
    "    maximizers = np.flatnonzero(estimate == estimate.max())\n",
    "    return rng.choice(maximizers)\n",
    "\n",
    "\n",
    "# you can probably infer opponent beliefs one step behind depending on whether\n",
    "# they sample again... so if they pull, pull again they won last time, if they\n",
    "# pull, move, the lost etc. if they pull, pull, move it was one-one...\n",
    "\n",
    "# keep opponent beliefs and the estimate weighted average of our beliefs\n",
    "# and theirs...\n",
    "\n",
    "def update():\n",
    "    global beliefs, supports, action_counts, time_since_op_pull\n",
    "\n",
    "    my_pull = my_pulls[-1]\n",
    "    op_pull = op_pulls[-1]\n",
    "    result = results[-1]\n",
    "\n",
    "    # bayesian update for the result of our pull\n",
    "    likelihood = np.ceil(supports[my_pull, :])\n",
    "    likelihood = (101.0 - likelihood) if result == 0 else likelihood\n",
    "    posterior = likelihood * beliefs[my_pull, :]\n",
    "    beliefs[my_pull, :] = posterior / posterior.sum()\n",
    "\n",
    "    # if the opponent repeats a first-time action, assume the first time is a success\n",
    "    if (action_counts[op_pull,1] == 2) and (op_pulls[-2] == op_pull):\n",
    "        likelihood = np.ceil(supports[op_pull, :])\n",
    "        posterior = likelihood * beliefs[op_pull, :]\n",
    "        beliefs[op_pull, :] = posterior / posterior.sum()    \n",
    "\n",
    "    # if the opponent hasn't pulled a lever in a long time then\n",
    "    # it is probably because the first time was a failure\n",
    "    for pull in np.where((action_counts[:,1] == 1) & (time_since_op_pull > 100)):\n",
    "        likelihood = 101 - np.ceil(supports[pull, :])\n",
    "        posterior = likelihood * beliefs[pull, :]\n",
    "        beliefs[pull, :] = posterior / posterior.sum()\n",
    "        time_since_op_pull[pull] = -np.inf\n",
    "\n",
    "    # decay in threshold due to pull\n",
    "    supports[my_pull, :] = 0.97 * supports[my_pull, :]\n",
    "\n",
    "    # decay due to opponent's pull\n",
    "    #supports[op_pull, :] = 0.97 * supports[op_pull, :]\n",
    "\n",
    "    # increment counts\n",
    "    action_counts[my_pull,0] += 1\n",
    "    action_counts[op_pull,1] += 1\n",
    "\n",
    "    # update time since pull\n",
    "    time_since_op_pull[op_pull] = 0\n",
    "    time_since_op_pull += 1\n",
    "    return\n",
    "\n",
    "# random number generator\n",
    "rng = np.random.default_rng(13)\n",
    "\n",
    "# belief distribution for the thresholds of each arm\n",
    "supports = np.tile(np.arange(101.0), (100, 1))\n",
    "beliefs = np.full_like(supports, 1 / 101.0)\n",
    "\n",
    "# game history\n",
    "step = 0\n",
    "my_pulls = np.array([], dtype=np.int)\n",
    "op_pulls = np.array([], dtype=np.int)\n",
    "results = np.array([], dtype=np.int)\n",
    "\n",
    "# the main function called by kaggle environment for each turn\n",
    "def agent(observation, configuration):\n",
    "    global total_reward, bandit_dict,conti\n",
    "    global step, my_pulls, op_pulls, results\n",
    "\n",
    "    my_pull = random.randrange(configuration['banditCount'])\n",
    "    if observation['step'] == 0:\n",
    "        total_reward = 0\n",
    "        bandit_dict = {}\n",
    "        conti=0\n",
    "        for x in range(configuration['banditCount']):\n",
    "            bandit_dict[x] = {'win': 1, 'loss': 0, 'opp': 0, 'my_continue': 0, 'op_continue': 0}\n",
    "            \n",
    "        return int(rng.integers(0, 100))  \n",
    "    else:\n",
    "        last_reward = observation['reward'] - total_reward\n",
    "        total_reward = observation['reward']\n",
    "        \n",
    "        my_idx = observation['agentIndex']\n",
    "        my_last_action = observation['lastActions'][my_idx]\n",
    "        op_last_action = observation['lastActions'][1-my_idx]\n",
    "        pre_wins.append(last_reward)\n",
    "        my_action_list.append(my_last_action)\n",
    "        op_action_list.append(op_last_action)\n",
    "        \n",
    "        if last_reward > 0:\n",
    "            bandit_dict[my_last_action]['win'] += 1\n",
    "        else:\n",
    "            bandit_dict[my_last_action]['loss'] += 1\n",
    "        bandit_dict[op_last_action]['opp'] += 1\n",
    "\n",
    "    my_pull = observation.lastActions[observation.agentIndex]\n",
    "    op_pull = observation.lastActions[1 - observation.agentIndex]\n",
    "    result = observation.reward - results.sum()\n",
    "\n",
    "    # update game history\n",
    "    my_pulls = np.append(my_pulls, my_pull)\n",
    "    op_pulls = np.append(op_pulls, op_pull)\n",
    "    results = np.append(results, result)\n",
    "    update()\n",
    "    if(last_reward>0):\n",
    "        my_pull=my_last_action\n",
    "        conti+=1\n",
    "        if (step>0 and step<200)or((step>600 and step<900))and((step>1700 and step<2000)):\n",
    "            return my_pull\n",
    "    if step>3 and (len(set(my_action_list[-4:]))==1)and(sum(results[-5:])>1):\n",
    "        my_pull = my_action_list[-1]\n",
    "        conti=0\n",
    "        if (step>700 and step<900):\n",
    "            return my_pull\n",
    "    if step>4 and (len(set(op_action_list[-3:]))==1) and step<600:\n",
    "         my_pull = op_action_list[-1]\n",
    "         conti=0   \n",
    "         return   my_pull\n",
    "           \n",
    "    if (step>700 and step<900):\n",
    "        conti=0\n",
    "        my_pull = get_next_bandit()\n",
    "        return my_pull\n",
    "    else:\n",
    "        my_pull =int(sample()) \n",
    "        conti=0\n",
    "        return my_pull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.009029,
     "end_time": "2021-01-26T20:33:34.084875",
     "exception": false,
     "start_time": "2021-01-26T20:33:34.075846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 16.9707,
   "end_time": "2021-01-26T20:33:34.203090",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-26T20:33:17.232390",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
